---
title: "Crash Course in Statistics"
author: "Alex F. Bokov"
date: "03/23/2015"
output: html_document
---

Let's suppose we have a cohort of patients, for whom measurement `Y` was collected. Let's say `Y` is the patient's response to some experimental drug. Let's say that the higher the value of `Y` is, the better the patient is doing. Values of `Y` close to zero mean that the drug is ineffective, and negative values of `Y` mean the drug is endangering the patient. 

First, lets read in some realistic patient vitals...

```{r}
options(width=300)
rawdeid <- read.delim('deid_bmi_temp.csv',head=T);
rawdeid$AGE <- rawdeid$AGE/365;
rawdeid$BMI <- as.numeric(as.character(rawdeid$BMI));
rawdeid$TEMPERATURE <- as.numeric(as.character(rawdeid$TEMPERATURE));
rawdeid$BMI <- as.numeric(as.character(rawdeid$BMI));
```

Let's create a binned BMI variable and make all unknowns into males for illustrative purposes, also simplify the race designations.
```{r}
rawdeid$BMI_BIN <- factor(sign(scale(rawdeid$BMI,center = 28.6)),labels=c('low','mid','hi'));
levels(rawdeid$BMI_BIN) <- c('low','hi','hi');
levels(rawdeid$SEX)<-c('f','m','m');
levels(rawdeid$RACE)<-ifelse((xx<-levels(rawdeid$RACE))%in%c('other','black','white'),xx,'other')
```

Now let's create a simulated response variable.
```{r,collapse=TRUE}
rawdeid$Y[rawdeid$SEX=='f']<- with(subset(rawdeid,SEX=='f'),-1+BMI/2.5+0.01*TEMPERATURE+rnorm(487178));
rawdeid$Y[rawdeid$SEX!='f']<- with(subset(rawdeid,SEX!='f'),17+0.007*TEMPERATURE-.002*AGE^2+rnorm(805297-487178));
rawdeid$Y[rawdeid$RACE=='black'&rawdeid$SEX=='f'] <- with(subset(rawdeid,RACE=='black'&SEX=='f'),Y+5-BMI/2-AGE^2*.001);
```

Now let's take a reasonable sample (800k+ is way too slow)
```{r}
rawdeid.sam <- subset(rawdeid, PATIENT_NUM %in% unique(c(sample(PATIENT_NUM,200),sample(unique(PATIENT_NUM[SEX=='f'&RACE=='black']),30))));
```

Plot Y vs BMI_BIN
```{r}
stripchart(Y~BMI_BIN,subset(rawdeid.sam,BMI<90),method = 'jitter',jitter = 0.2,col=c('#FF000010','#0000FF10'),vertical = T,pch='.',cex=8)
```

Now let's do a T-test comparing the response of low-BMI and high-BMI patients.
```{r}
t.test(Y~BMI_BIN,subset(rawdeid.sam,BMI<90));
```

Plot Y vs SEX
```{r}
stripchart(Y~SEX,subset(rawdeid.sam,BMI<90),method = 'jitter',jitter = 0.2, col=c('#FF000010','#0000FF10'),vertical = T,pch='.',cex=8)
```

Now let's do the same thing but comparing the response of females and males.
```{r}
t.test(Y~SEX,subset(rawdeid.sam,BMI<90));
```

By the way, a T-test is just a special case of regression. Look:
```{r}
summary(lm(Y~SEX,subset(rawdeid.sam,BMI<90)));
```



Plot Y vs SEX _and_ BMI_BIN
```{r}
stripchart(Y~SEX+BMI_BIN,subset(rawdeid.sam,BMI<90),method = 'jitter',jitter = 0.2,col=c('#FF000010','#0000FF10'),vertical = T,pch='.',cex=8)
```

Woow. Looks like males and females have a different response after all. Why did our t-test come back non-significant?

We could have a bunch of T-tests comparing various combinations of sex and BMI. But there is a proper way to do this.
```{r}
anova(aov(Y~SEX+BMI_BIN,subset(rawdeid.sam,BMI<90)));
```

But guess what? ANOVA is _also_ just a (usually inconvenient) way of presenting results from regression analysis:
```{r}
anova(lm(Y~SEX+BMI_BIN,subset(rawdeid.sam,BMI<90)));
```

Notice, `anova()` is just a wrapper function around a fitted model. So if ANOVA is an inconvenient way of looking at the data, what's better? How about the coefficients of the regression model itself?
```{r}
summary(lm(Y~SEX+BMI_BIN,subset(rawdeid.sam,BMI<90)));
```

The problem, though is that we are still not capturing the fact that the BMI effect is _conditional_ on whether or not the patient is male! To probe this "criss-cross" behavior, we need an interaction term:
```{r}
summary(lm(Y~SEX+BMI_BIN+SEX:BMI_BIN,subset(rawdeid.sam,BMI<90)));
```

A shorthand for `SEX+BMI_BIN+SEX:BMI_BIN` is `SEX*BMI_BIN`:
```{r}
summary(lm(Y~SEX*BMI_BIN,subset(rawdeid.sam,BMI<90)));
```

But, a linear regression model like the ones fitted by `lm()` doesn't require that the variables be discrete. BMI is naturally a numeric variable, so why not let it stay that way?
Plot Y vs SEX and _unbinned_ BMI
```{r}
plot(Y~BMI,subset(rawdeid.sam,BMI<90&SEX=='m'),ylim=c(0,30),pch='.',cex=8,col="#0000FF20");
points(Y~BMI,subset(rawdeid.sam,BMI<90&SEX=='f'),pch='.',cex=8,col="#FF000020");
```

Here is the regression model.
```{r}
sexbmi <- lm(Y~SEX*BMI,subset(rawdeid.sam,BMI<90));
summary(sexbmi);
```

Is this a good fit? Let's plot it and find out.
```{r}
plot(sexbmi,pch='.',cex=10,col="#00000030");
```

No. Not at all. There is an additional source of variability that is not accounted for by this model.

Plot Y vs SEX and AGE
```{r}
plot(Y~AGE,subset(rawdeid.sam,BMI<90&SEX=='m'),ylim=c(0,30),pch='.',cex=8,col="#0000FF20");
points(Y~AGE,subset(rawdeid.sam,BMI<90&SEX=='f'),pch='.',cex=8,col="#FF000020");
```

But really, `Y~AGE` and `Y~BMI` are both two-dimensional projections of a three-dimensional cloud of data.

Let's install some prerequisite packages for 3D plotting....
```{r}
# rglwidget
require('rglwidget');require('htmlwidgets');require('htmltools');require('rgl');require('plot3Drgl');
require('plot3D');require('misc3d');
```

Now let's see these data-points in their full glory...
```{r}
library(plot3Drgl); #library(knitr);

#src<-paste("file://", writeWebGL(dir=tempdir(), width=700), sep="");
yVbmi <- matrix(c(0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,1),nrow=4,byrow = T);
yVage <- matrix(c(1,0,0,0,0,0,1,0,0,-1,0,0,0,0,0,1),nrow=4,byrow=T);
```

```{r setup}
library(knitr);
knit_hooks$set(webgl = hook_webgl)
```

```{r firstplot}
with(subset(rawdeid.sam,BMI<90),
     scatter3Drgl(AGE,BMI,Y,colvar=as.numeric(SEX),
                  col=c('#FF000010','#0000FF10'),xlab='Age',ylab='BMI',zlab='Y',FOV=0));

browseURL(paste("file://", writeWebGL(dir=tempdir(), width=700), sep=""));
```

The `Y~AGE` projection...
```{r ageproj}
par3d(userMatrix=yVage);
```

The `Y~BMI` projection...
```{r bmiproj}
par3d(userMatrix=yVbmi);
```

...and there is no reason at all why it must be limited to two dimensions. There will be as many dimensions are there are numeric variables.

We better update the regression model to include age.
```{r}
sexbmiage <- update(sexbmi,.~.*AGE);
summary(sexbmiage);
```

How normal are the residuals now?
```{r}
plot(sexbmiage,pch='.',cex=10,col="#00000030");
```

Some evidence of non-linearity, but much better than before. But do we _really_ need _all_ these terms? How do we decide which ones to keep?
```{r}
sexbmiage.aic <- step(sexbmiage,scope=list(.~1,.~.),direction = "both");
summary(sexbmiage.aic);
```

We got rid of the three-way interaction term. Check the residuals.
```{r}
plot(sexbmiage.aic,pch='.',cex=10,col="#00000030");


```

Not visibly worse. But there is something else to keep in mind-- these data-points are not independent! Some of them come from the same individual sampled at multiple ages! To separately account for within-indvididual and between-individual variation, we need to use the `nlme` library.
```{r}
library(nlme);
```

Now, do some minor dark magic that we won't have time to discuss.
```{r}
lmec <- lmeControl(opt='optim',maxIter=100,msMaxIter=100,niterEM=50,msMaxEval=400,nlmStepMax=200);
```

The `lme()` function is for fitting a *L*inear *M*ixed *E*ffect model. Mixed-effect means some of the effects are "fixed", like the ones we've been using up to now, and some of them are "random"-- i.e. error terms, but now there are more than one of them. But before we do that, let's see if it's worth doing. Let's fit a `gls()` model, which doesn't use random effects, and it will allow a comparison with the `lme()` model to see if it makes a difference.
```{r}
sexbmiage.gls <- gls(sexbmiage.aic$call$formula,rawdeid.sam,subset=BMI<90,na.action=na.omit,method='ML');
summary(sexbmiage.gls)$tTable;
summary(sexbmiage.aic)$coef;
```

Now let's try fitting an `lme()` model.
```{r}
sexbmiage.lme <- lme(sexbmiage.aic$call$formula,rawdeid.sam,subset=BMI<90,method='ML',na.action=na.omit,random=~1|PATIENT_NUM);
summary(sexbmiage.lme)$tTable;
```

Is the `lme()` model a significantly better fit than the fixed-effect model? At last, something that `anova()` _is_ useful for.
```{r}
anova(sexbmiage.gls,sexbmiage.lme);
```

So far we've said: each patient has a unique baseline value, but they all have the same age and BMI effect. Let's see if that's actually true.
```{r}
sexbmiage.lmeA <- update(sexbmiage.lme,random=~AGE|PATIENT_NUM,control=lmec);
sexbmiage.lmeB <- update(sexbmiage.lme,random=~BMI|PATIENT_NUM,control=lmec);

anova(sexbmiage.lme,sexbmiage.lmeA);
anova(sexbmiage.lme,sexbmiage.lmeB);
```

So, we are better off with a random `BMI` term in addition to a random baseline. Note: we have attributed some but not all of the BMI effect to individual variation. Now there is both a fixed `BMI` effect and a random `BMI` effect. It might also be worth seeing if including both both `BMI` _and_ `AGE` as random terms further improves fit. However, this would be something to run on a fast machine over a lunch-break.
```{r}
#sexbmiage.lmeAB <- update(sexbmiage.lmeA,random=~AGE+BMI|PATIENT_NUM,control=lmec);
#anova(sexbmiage.lmeA,sexbmiage.lmeAB);
#anova(sexbmiage.lmeB,sexbmiage.lmeAB);
```

Standardized residuals look better now.
```{r}
plot(sexbmiage.lmeA);
```

Not bad! But, what if I told you there was an additional variable available: `RACE`? When I simulated the `Y` variable, for Black women only, I gave it a strong inverse correlation with `BMI` and `AGE`^2. So strong that at higher values `Y` becomes negative, and at the beginning I stipulated that a negative `Y` means the patient is in danger! Do we have enough of a sample (of unique patients) to detect this?
```{r}
cbind(table(unique(rawdeid.sam[,c('PATIENT_NUM','RACE')])$RACE))
```

Let's find out.
```{r}
try(sexbmiagerace.lmeA <- update(sexbmiage.lmeA,.~.:RACE+RACE,control=lmec,subset=BMI<90));
try(sexbmiagerace.lmeB <- update(sexbmiage.lmeB,.~.:RACE+RACE,control=lmec,subset=BMI<90));
try(anova(sexbmiage.lmeA,sexbmiagerace.lmeA));
try(anova(sexbmiage.lmeB,sexbmiagerace.lmeB));
```

So, for Black women only, this hypothetical drug would be hazardous, and strongly counter-indicated. Yet, if we used too small a sample size, or one with too few Black women in it, _we would not have noticed_. If we had added `RACE` to the model and ran `step()` it would have said that `RACE` is not a significant source of variation. In other words, any of the following can result in data being misinterpreted potentially putting patients at risk:

* Excessively small sample sizes.
* Sampling bias.
* Omitting relevant variables.
* Including too many irrelevant variables.
* Not checking the residuals on what you think is an appropriate model.

<!--
Plot Y vs SEX and TEMPERATURE
```{r}
#plot(Y~TEMPERATURE,subset(rawdeid.sam,BMI<90&SEX=='m'),ylim=c(0,30),pch='.',cex=10,col="#0000FF30");
#points(Y~TEMPERATURE,subset(rawdeid.sam,BMI<90&SEX=='f'),pch='.',cex=10,col="#FF000030");
```

Plot all the data
```{r}
#plot(subset(cbind(jitter(data.matrix(rawdeid[,2:3])),rawdeid[,4:6]),BMI<90 & TEMPERATURE>91 & TEMPERATURE<104),pch='.',cex=2,col='#00000002');
```
-->
